# MLOps Assignment 2 - Cats vs Dogs Classification

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.1-red.svg)](https://pytorch.org/)
[![MLflow](https://img.shields.io/badge/MLflow-2.10-blue.svg)](https://mlflow.org/)

**Course:** AIMLCZG523 - MLOps
**Institution:** BITS Pilani (WILP)
**Student ID:** 2024aa05820

## üìã Project Overview

Binary image classification system for a pet adoption platform to automatically categorize uploaded pet images as either **cats** or **dogs**. This project demonstrates end-to-end MLOps practices including:

- **M1:** Model Development & Experiment Tracking
- **M2:** Model Packaging & Containerization
- **M3:** CI Pipeline for Build, Test & Image Creation
- **M4:** CD Pipeline & Deployment
- **M5:** Monitoring, Logs & Final Submission

## üèóÔ∏è Project Structure

```
mlops-assignment2/
‚îú‚îÄ‚îÄ .github/workflows/       # GitHub Actions CI/CD pipelines
‚îú‚îÄ‚îÄ .dvc/                    # DVC configuration
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/                 # Raw dataset (DVC tracked)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ train/           # Training data (80%)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ val/             # Validation data (10%)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ test/            # Test data (10%)
‚îÇ   ‚îî‚îÄ‚îÄ processed/           # Preprocessed data
‚îú‚îÄ‚îÄ deploy/k8s/              # Kubernetes manifests
‚îú‚îÄ‚îÄ grafana/                 # Grafana dashboards
‚îú‚îÄ‚îÄ models/                  # Saved model artifacts
‚îú‚îÄ‚îÄ mlruns/                  # MLflow tracking data
‚îú‚îÄ‚îÄ notebooks/               # Jupyter notebooks
‚îú‚îÄ‚îÄ reports/                 # Generated reports (confusion matrix, etc.)
‚îú‚îÄ‚îÄ scripts/                 # Utility scripts
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api/                 # FastAPI application
‚îÇ   ‚îú‚îÄ‚îÄ config/              # Configuration files
‚îÇ   ‚îú‚îÄ‚îÄ data/                # Data loading & preprocessing
‚îÇ   ‚îî‚îÄ‚îÄ models/              # Model architecture & training
‚îú‚îÄ‚îÄ tests/                   # Unit tests
‚îú‚îÄ‚îÄ .gitignore
‚îú‚îÄ‚îÄ .dvcignore
‚îú‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ Makefile
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

## üöÄ Quick Start

### Prerequisites

- Python 3.11+
- Git
- Kaggle account (for dataset download)
- Docker (for containerization)
- kubectl & Minikube (for deployment)

### Step-by-Step Setup

#### Step 1: Clone the Repository

```bash
git clone https://github.com/2024aa05820/mlops-assignment2.git
cd mlops-assignment2
```

#### Step 2: Create Virtual Environment & Install Dependencies

```bash
# Create and activate virtual environment
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate

# Install dependencies
pip install --upgrade pip
pip install -r requirements.txt

# Or use make command
make init
source .venv/bin/activate
```

#### Step 3: Configure Kaggle API

The dataset is downloaded from: https://www.kaggle.com/datasets/bhavikjikadara/dog-and-cat-classification-dataset

**Option A: Using API Token (Recommended)**

```bash
# 1. Go to https://www.kaggle.com/settings
# 2. Scroll to "API" section
# 3. Click "Create New Token" - copy the token shown

# 4. Set the environment variable
export KAGGLE_API_TOKEN=your_token_here

# For persistence, add to your shell profile:
echo 'export KAGGLE_API_TOKEN=your_token_here' >> ~/.bashrc
# or for zsh:
echo 'export KAGGLE_API_TOKEN=your_token_here' >> ~/.zshrc
```

**Option B: Using kaggle.json file**

```bash
# If kaggle.json was downloaded:
mkdir -p ~/.kaggle
mv ~/Downloads/kaggle.json ~/.kaggle/
chmod 600 ~/.kaggle/kaggle.json
```

#### Step 4: Download Dataset & Initialize DVC

```bash
# Option A: Run all data setup in one command
make data-setup

# Option B: Run steps individually
make download      # Download and split Kaggle dataset
make dvc-init      # Initialize DVC
make dvc-add       # Add data to DVC tracking
```

#### Step 5: Train the Model

```bash
# Train with default configuration
make train

# Or run directly with custom parameters
python src/models/train.py --epochs 10 --batch-size 32 --lr 0.001
```

#### Step 6: View Experiment Results in MLflow

```bash
# Start MLflow UI
make mlflow-ui

# Open browser at http://localhost:5000
```

#### Step 7: Run the API Server (Local)

```bash
# Start FastAPI server
make serve

# API will be available at http://localhost:8000
# Swagger docs at http://localhost:8000/docs
```

#### Step 8: Build & Run Docker Container

```bash
# Build Docker image
make docker-build

# Run container
make docker-run

# Test the API
curl http://localhost:8000/health

# Stop container
make docker-stop
```

#### Step 9: Deploy to Kubernetes

```bash
# Start Minikube (if not running)
minikube start

# Deploy application
make deploy

# Check status
make k8s-status

# View logs
make k8s-logs
```

## üìä Model Architecture

**SimpleCNN** - A lightweight CNN for binary classification:

| Layer | Output Shape | Parameters |
|-------|--------------|------------|
| Conv2D Block 1 | 32 √ó 112 √ó 112 | 896 |
| Conv2D Block 2 | 64 √ó 56 √ó 56 | 18,496 |
| Conv2D Block 3 | 128 √ó 28 √ó 28 | 73,856 |
| Conv2D Block 4 | 256 √ó 14 √ó 14 | 295,168 |
| Global Avg Pool | 256 √ó 1 √ó 1 | 0 |
| FC Layer 1 | 128 | 32,896 |
| FC Layer 2 | 2 | 258 |
| **Total** | | **~421K** |

## üîß Available Make Commands

```bash
make help          # Show all available commands

# Environment
make init          # Create venv and install dependencies
make install       # Install dependencies only

# Data
make download      # Download dataset from Kaggle
make dvc-init      # Initialize DVC
make dvc-add       # Add data to DVC tracking
make data-setup    # Full data setup (download + DVC)

# Training
make train         # Train the model

# API
make serve         # Start FastAPI server locally

# Testing
make test          # Run tests with coverage
make test-quick    # Run tests without coverage

# Code Quality
make lint          # Run linter (ruff)
make format        # Format code (black + ruff)

# Docker
make docker-build  # Build Docker image
make docker-run    # Run Docker container
make docker-stop   # Stop and remove container

# Kubernetes
make deploy        # Deploy to Kubernetes
make k8s-status    # Check deployment status
make k8s-logs      # View application logs

# MLflow
make mlflow-ui     # Start MLflow UI

# Cleanup
make clean         # Clean generated files
```

## üìà MLflow Experiment Tracking

The training script automatically logs to MLflow:

- **Parameters:** learning_rate, batch_size, epochs, dropout, etc.
- **Metrics:** train/val loss, accuracy, precision, recall, F1 score
- **Artifacts:** confusion matrix, training curves, model checkpoint

## üß™ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/health` | GET | Health check |
| `/predict` | POST | Predict cat/dog from image |
| `/metrics` | GET | Prometheus metrics |
| `/docs` | GET | Swagger UI documentation |

## üì¶ Technology Stack

| Component | Technology |
|-----------|------------|
| Language | Python 3.11+ |
| ML Framework | PyTorch 2.1 |
| API Framework | FastAPI |
| Experiment Tracking | MLflow |
| Data Versioning | DVC |
| Containerization | Docker |
| Orchestration | Kubernetes (Minikube) |
| CI/CD | GitHub Actions |
| Monitoring | Prometheus + Grafana |
| Infrastructure | Rocky Linux / RHEL |

## üìù License

This project is for educational purposes as part of BITS Pilani WILP MLOps course.

